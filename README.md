# ðŸ“„ PDF RAG Chatbot

An end-to-end Retrieval-Augmented Generation (RAG) application that allows users to interact with the contents of a PDF through natural language queries. This project combines document processing, vector similarity search, and large language models to deliver a contextual question-answering experience.

## ðŸš€ Features

- Upload any PDF document
- Extracts and chunks text from PDF
- Generates vector embeddings using OpenAI
- Stores and searches chunks using FAISS (vector database)
- Injects context into prompts for LLM-based answers
- User-friendly chat interface (built with Streamlit)

## ðŸ§  Tech Stack

- **LangChain** â€“ RAG pipeline and LLM integration
- **OpenAI GPT-3.5/GPT-4** â€“ Answer generation
- **FAISS** â€“ Vector similarity search
- **Streamlit** â€“ Frontend interface
- **PyPDF2 / pdfplumber** â€“ PDF text extraction
- **tiktoken** â€“ Token management for chunking

## ðŸ“‚ Folder Structure

pdf-rag/
â”œâ”€â”€ app.py # Streamlit app
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project overview

## ðŸ”§ Setup Instructions

1. **Clone the repository**
```bash
git clone https://github.com/Anshmittal86/pdf-rag.git
cd pdf-rag
```
2. Create and activate virtual environment.
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Create and activate virtual environment.
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

4. Add your GEMINI API key
Create a .env file and add:
GEMINI_API_KEY=your_openai_api_key_here

5. Run the app
```bash
streamlit run app.py
```

## Example Use Cases
- Legal or technical document understanding
- Academic paper Q&A
- Internal documentation search assistant

## Future Enhancements
- Chat history and memory
- Support for DOCX, TXT, and web pages
